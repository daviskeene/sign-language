{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense, Flatten, BatchNormalization, Conv2D, MaxPool2D, Dropout\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from keras.metrics import categorical_crossentropy\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import itertools\n",
    "import random\n",
    "import warnings\n",
    "import numpy as np\n",
    "import cv2\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sign Language Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) Create a dictionary of numbers to letters so that we can decode the message at the end of training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_dict = {}\n",
    "\n",
    "letter_idx = 97\n",
    "for i in range(26):\n",
    "    word_dict[i] = chr(letter_idx)\n",
    "    letter_idx += 1\n",
    "\n",
    "print(word_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) Initialize the train and test batches with the ImageDataGenerator object "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = './data/train'\n",
    "test_path = './data/test'\n",
    "\n",
    "# batch_size = How many do we want to predict? chooses images at random \n",
    "batch_size = 20\n",
    "class_mode = 'categorical'\n",
    "target_size = (64, 64)\n",
    "train_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input).flow_from_directory(directory=train_path, target_size=target_size, class_mode=class_mode, batch_size=batch_size,shuffle=True)\n",
    "test_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input).flow_from_directory(directory=test_path, target_size=target_size, class_mode=class_mode, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "imgs, labels = next(train_batches)\n",
    "\n",
    "print(\"Batched train and test images...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the Model\n",
    "#### 1) Create the model that correctly classifies each of the letters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "print(\"model 1\")\n",
    "model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=(64,64,3)))\n",
    "model.add(MaxPool2D(pool_size=(2, 2), strides=2))\n",
    "\n",
    "print(\"First convolution...\")\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding = 'same'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2), strides=2))\n",
    "\n",
    "print(\"Second convolution...\")\n",
    "\n",
    "model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding = 'valid'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2), strides=2))\n",
    "\n",
    "print(\"Convolutions done\")\n",
    "print(\"Flattening...\")\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(64,activation =\"relu\"))\n",
    "model.add(Dense(128,activation =\"relu\"))\n",
    "model.add(Dense(128,activation =\"relu\"))\n",
    "model.add(Dense(5,activation =\"softmax\"))\n",
    "# Softmax must be equivalent to the number of classifications (26 for full alphabet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) We compile and define the loss functions here so that we can create a fitted model in the next step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Compiling with ADAM model...\")\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=1, min_lr=0.0001)\n",
    "early_stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=2, verbose=0, mode='auto')\n",
    "\n",
    "print(\"Compiling with SGD model...\")\n",
    "\n",
    "model.compile(optimizer=SGD(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=1, min_lr=0.0005)\n",
    "early_stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=2, verbose=0, mode='auto')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) Fit and save the model using the loss functions defined above "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Fitting model...\")\n",
    "fitted_model = model.fit(train_batches, epochs=9, callbacks=[reduce_lr, early_stop],  validation_data = test_batches)#, checkpoint])\n",
    "\n",
    "imgs, labels = next(test_batches) # For getting next batch of imgs...\n",
    "\n",
    "scores = model.evaluate(imgs, labels, verbose=0)\n",
    "print(f'{model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
    "\n",
    "print(\"Saving model...\")\n",
    "model.save('best_model_dataflair3.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(r\"best_model_dataflair3.h5\")\n",
    "\n",
    "imgs, labels = next(test_batches)\n",
    "\n",
    "scores = model.evaluate(imgs, labels, verbose=0)\n",
    "print(f'{model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
    "\n",
    "model.summary()\n",
    "\n",
    "scores #[loss, accuracy] on test data...\n",
    "model.metrics_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) Test the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1385 images belonging to 26 classes.\n",
      "Found 120 images belonging to 26 classes.\n",
      "Batched train and test images...\n",
      "(5, 64, 64, 3)\n",
      "[[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0.]]\n",
      "model 1\n",
      "First convolution...\n",
      "Second convolution...\n",
      "Convolutions done\n",
      "Flattening...\n",
      "Compiling...\n",
      "Compiling 2...\n",
      "<keras.callbacks.ReduceLROnPlateau object at 0x7fc2106710a0>\n",
      "<keras.callbacks.EarlyStopping object at 0x7fc2106717f0>\n",
      "Fitting model...\n",
      "Epoch 1/9\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": " logits and labels must be broadcastable: logits_size=[5,5] labels_size=[5,26]\n\t [[node categorical_crossentropy/softmax_cross_entropy_with_logits\n (defined at /Users/meghamattikalli/opt/anaconda3/lib/python3.8/site-packages/keras/backend.py:5009)\n]] [Op:__inference_train_function_99419]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node categorical_crossentropy/softmax_cross_entropy_with_logits:\nIn[0] categorical_crossentropy/softmax_cross_entropy_with_logits/Reshape:\t\nIn[1] categorical_crossentropy/softmax_cross_entropy_with_logits/Reshape_1:\n\nOperation defined at: (most recent call last)\n>>>   File \"/Users/meghamattikalli/opt/anaconda3/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n>>>     return _run_code(code, main_globals, None,\n>>> \n>>>   File \"/Users/meghamattikalli/opt/anaconda3/lib/python3.8/runpy.py\", line 87, in _run_code\n>>>     exec(code, run_globals)\n>>> \n>>>   File \"/Users/meghamattikalli/opt/anaconda3/lib/python3.8/site-packages/ipykernel_launcher.py\", line 16, in <module>\n>>>     app.launch_new_instance()\n>>> \n>>>   File \"/Users/meghamattikalli/opt/anaconda3/lib/python3.8/site-packages/traitlets/config/application.py\", line 845, in launch_instance\n>>>     app.start()\n>>> \n>>>   File \"/Users/meghamattikalli/opt/anaconda3/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 612, in start\n>>>     self.io_loop.start()\n>>> \n>>>   File \"/Users/meghamattikalli/opt/anaconda3/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 149, in start\n>>>     self.asyncio_loop.run_forever()\n>>> \n>>>   File \"/Users/meghamattikalli/opt/anaconda3/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n>>>     self._run_once()\n>>> \n>>>   File \"/Users/meghamattikalli/opt/anaconda3/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n>>>     handle._run()\n>>> \n>>>   File \"/Users/meghamattikalli/opt/anaconda3/lib/python3.8/asyncio/events.py\", line 81, in _run\n>>>     self._context.run(self._callback, *self._args)\n>>> \n>>>   File \"/Users/meghamattikalli/opt/anaconda3/lib/python3.8/site-packages/tornado/ioloop.py\", line 690, in <lambda>\n>>>     lambda f: self._run_callback(functools.partial(callback, future))\n>>> \n>>>   File \"/Users/meghamattikalli/opt/anaconda3/lib/python3.8/site-packages/tornado/ioloop.py\", line 743, in _run_callback\n>>>     ret = callback()\n>>> \n>>>   File \"/Users/meghamattikalli/opt/anaconda3/lib/python3.8/site-packages/tornado/gen.py\", line 787, in inner\n>>>     self.run()\n>>> \n>>>   File \"/Users/meghamattikalli/opt/anaconda3/lib/python3.8/site-packages/tornado/gen.py\", line 748, in run\n>>>     yielded = self.gen.send(value)\n>>> \n>>>   File \"/Users/meghamattikalli/opt/anaconda3/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 365, in process_one\n>>>     yield gen.maybe_future(dispatch(*args))\n>>> \n>>>   File \"/Users/meghamattikalli/opt/anaconda3/lib/python3.8/site-packages/tornado/gen.py\", line 209, in wrapper\n>>>     yielded = next(result)\n>>> \n>>>   File \"/Users/meghamattikalli/opt/anaconda3/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 268, in dispatch_shell\n>>>     yield gen.maybe_future(handler(stream, idents, msg))\n>>> \n>>>   File \"/Users/meghamattikalli/opt/anaconda3/lib/python3.8/site-packages/tornado/gen.py\", line 209, in wrapper\n>>>     yielded = next(result)\n>>> \n>>>   File \"/Users/meghamattikalli/opt/anaconda3/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 543, in execute_request\n>>>     self.do_execute(\n>>> \n>>>   File \"/Users/meghamattikalli/opt/anaconda3/lib/python3.8/site-packages/tornado/gen.py\", line 209, in wrapper\n>>>     yielded = next(result)\n>>> \n>>>   File \"/Users/meghamattikalli/opt/anaconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 306, in do_execute\n>>>     res = shell.run_cell(code, store_history=store_history, silent=silent)\n>>> \n>>>   File \"/Users/meghamattikalli/opt/anaconda3/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n>>>     return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n>>> \n>>>   File \"/Users/meghamattikalli/opt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2877, in run_cell\n>>>     result = self._run_cell(\n>>> \n>>>   File \"/Users/meghamattikalli/opt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2923, in _run_cell\n>>>     return runner(coro)\n>>> \n>>>   File \"/Users/meghamattikalli/opt/anaconda3/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n>>>     coro.send(None)\n>>> \n>>>   File \"/Users/meghamattikalli/opt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3146, in run_cell_async\n>>>     has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n>>> \n>>>   File \"/Users/meghamattikalli/opt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3338, in run_ast_nodes\n>>>     if (await self.run_code(code, result,  async_=asy)):\n>>> \n>>>   File \"/Users/meghamattikalli/opt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3418, in run_code\n>>>     exec(code_obj, self.user_global_ns, self.user_ns)\n>>> \n>>>   File \"<ipython-input-20-c234c42e8995>\", line 90, in <module>\n>>>     history2 = model.fit(train_batches, epochs=9, callbacks=[reduce_lr, early_stop],  validation_data = test_batches)#, checkpoint])\n>>> \n>>>   File \"/Users/meghamattikalli/opt/anaconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"/Users/meghamattikalli/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 1216, in fit\n>>>     tmp_logs = self.train_function(iterator)\n>>> \n>>>   File \"/Users/meghamattikalli/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 878, in train_function\n>>>     return step_function(self, iterator)\n>>> \n>>>   File \"/Users/meghamattikalli/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 867, in step_function\n>>>     outputs = model.distribute_strategy.run(run_step, args=(data,))\n>>> \n>>>   File \"/Users/meghamattikalli/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 860, in run_step\n>>>     outputs = model.train_step(data)\n>>> \n>>>   File \"/Users/meghamattikalli/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 809, in train_step\n>>>     loss = self.compiled_loss(\n>>> \n>>>   File \"/Users/meghamattikalli/opt/anaconda3/lib/python3.8/site-packages/keras/engine/compile_utils.py\", line 201, in __call__\n>>>     loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n>>> \n>>>   File \"/Users/meghamattikalli/opt/anaconda3/lib/python3.8/site-packages/keras/losses.py\", line 141, in __call__\n>>>     losses = call_fn(y_true, y_pred)\n>>> \n>>>   File \"/Users/meghamattikalli/opt/anaconda3/lib/python3.8/site-packages/keras/losses.py\", line 245, in call\n>>>     return ag_fn(y_true, y_pred, **self._fn_kwargs)\n>>> \n>>>   File \"/Users/meghamattikalli/opt/anaconda3/lib/python3.8/site-packages/keras/losses.py\", line 1664, in categorical_crossentropy\n>>>     return backend.categorical_crossentropy(\n>>> \n>>>   File \"/Users/meghamattikalli/opt/anaconda3/lib/python3.8/site-packages/keras/backend.py\", line 5009, in categorical_crossentropy\n>>>     return tf.nn.softmax_cross_entropy_with_logits(\n>>> ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-c234c42e8995>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mearly_stop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Fitting model...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m \u001b[0mhistory2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mreduce_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stop\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#, checkpoint])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0mimgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_batches\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# For getting next batch of imgs...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     56\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     59\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     60\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m:  logits and labels must be broadcastable: logits_size=[5,5] labels_size=[5,26]\n\t [[node categorical_crossentropy/softmax_cross_entropy_with_logits\n (defined at /Users/meghamattikalli/opt/anaconda3/lib/python3.8/site-packages/keras/backend.py:5009)\n]] [Op:__inference_train_function_99419]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node categorical_crossentropy/softmax_cross_entropy_with_logits:\nIn[0] categorical_crossentropy/softmax_cross_entropy_with_logits/Reshape:\t\nIn[1] categorical_crossentropy/softmax_cross_entropy_with_logits/Reshape_1:\n\nOperation defined at: (most recent call last)\n>>>   File \"/Users/meghamattikalli/opt/anaconda3/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n>>>     return _run_code(code, main_globals, None,\n>>> \n>>>   File \"/Users/meghamattikalli/opt/anaconda3/lib/python3.8/runpy.py\", line 87, in _run_code\n>>>     exec(code, run_globals)\n>>> \n>>>   File \"/Users/meghamattikalli/opt/anaconda3/lib/python3.8/site-packages/ipykernel_launcher.py\", line 16, in <module>\n>>>     app.launch_new_instance()\n>>> \n>>>   File \"/Users/meghamattikalli/opt/anaconda3/lib/python3.8/site-packages/traitlets/config/application.py\", line 845, in launch_instance\n>>>     app.start()\n>>> \n>>>   File \"/Users/meghamattikalli/opt/anaconda3/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 612, in start\n>>>     self.io_loop.start()\n>>> \n>>>   File \"/Users/meghamattikalli/opt/anaconda3/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 149, in start\n>>>     self.asyncio_loop.run_forever()\n>>> \n>>>   File \"/Users/meghamattikalli/opt/anaconda3/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n>>>     self._run_once()\n>>> \n>>>   File \"/Users/meghamattikalli/opt/anaconda3/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n>>>     handle._run()\n>>> \n>>>   File \"/Users/meghamattikalli/opt/anaconda3/lib/python3.8/asyncio/events.py\", line 81, in _run\n>>>     self._context.run(self._callback, *self._args)\n>>> \n>>>   File \"/Users/meghamattikalli/opt/anaconda3/lib/python3.8/site-packages/tornado/ioloop.py\", line 690, in <lambda>\n>>>     lambda f: self._run_callback(functools.partial(callback, future))\n>>> \n>>>   File \"/Users/meghamattikalli/opt/anaconda3/lib/python3.8/site-packages/tornado/ioloop.py\", line 743, in _run_callback\n>>>     ret = callback()\n>>> \n>>>   File \"/Users/meghamattikalli/opt/anaconda3/lib/python3.8/site-packages/tornado/gen.py\", line 787, in inner\n>>>     self.run()\n>>> \n>>>   File \"/Users/meghamattikalli/opt/anaconda3/lib/python3.8/site-packages/tornado/gen.py\", line 748, in run\n>>>     yielded = self.gen.send(value)\n>>> \n>>>   File \"/Users/meghamattikalli/opt/anaconda3/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 365, in process_one\n>>>     yield gen.maybe_future(dispatch(*args))\n>>> \n>>>   File \"/Users/meghamattikalli/opt/anaconda3/lib/python3.8/site-packages/tornado/gen.py\", line 209, in wrapper\n>>>     yielded = next(result)\n>>> \n>>>   File \"/Users/meghamattikalli/opt/anaconda3/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 268, in dispatch_shell\n>>>     yield gen.maybe_future(handler(stream, idents, msg))\n>>> \n>>>   File \"/Users/meghamattikalli/opt/anaconda3/lib/python3.8/site-packages/tornado/gen.py\", line 209, in wrapper\n>>>     yielded = next(result)\n>>> \n>>>   File \"/Users/meghamattikalli/opt/anaconda3/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 543, in execute_request\n>>>     self.do_execute(\n>>> \n>>>   File \"/Users/meghamattikalli/opt/anaconda3/lib/python3.8/site-packages/tornado/gen.py\", line 209, in wrapper\n>>>     yielded = next(result)\n>>> \n>>>   File \"/Users/meghamattikalli/opt/anaconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 306, in do_execute\n>>>     res = shell.run_cell(code, store_history=store_history, silent=silent)\n>>> \n>>>   File \"/Users/meghamattikalli/opt/anaconda3/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n>>>     return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n>>> \n>>>   File \"/Users/meghamattikalli/opt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2877, in run_cell\n>>>     result = self._run_cell(\n>>> \n>>>   File \"/Users/meghamattikalli/opt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2923, in _run_cell\n>>>     return runner(coro)\n>>> \n>>>   File \"/Users/meghamattikalli/opt/anaconda3/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n>>>     coro.send(None)\n>>> \n>>>   File \"/Users/meghamattikalli/opt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3146, in run_cell_async\n>>>     has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n>>> \n>>>   File \"/Users/meghamattikalli/opt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3338, in run_ast_nodes\n>>>     if (await self.run_code(code, result,  async_=asy)):\n>>> \n>>>   File \"/Users/meghamattikalli/opt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3418, in run_code\n>>>     exec(code_obj, self.user_global_ns, self.user_ns)\n>>> \n>>>   File \"<ipython-input-20-c234c42e8995>\", line 90, in <module>\n>>>     history2 = model.fit(train_batches, epochs=9, callbacks=[reduce_lr, early_stop],  validation_data = test_batches)#, checkpoint])\n>>> \n>>>   File \"/Users/meghamattikalli/opt/anaconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"/Users/meghamattikalli/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 1216, in fit\n>>>     tmp_logs = self.train_function(iterator)\n>>> \n>>>   File \"/Users/meghamattikalli/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 878, in train_function\n>>>     return step_function(self, iterator)\n>>> \n>>>   File \"/Users/meghamattikalli/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 867, in step_function\n>>>     outputs = model.distribute_strategy.run(run_step, args=(data,))\n>>> \n>>>   File \"/Users/meghamattikalli/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 860, in run_step\n>>>     outputs = model.train_step(data)\n>>> \n>>>   File \"/Users/meghamattikalli/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 809, in train_step\n>>>     loss = self.compiled_loss(\n>>> \n>>>   File \"/Users/meghamattikalli/opt/anaconda3/lib/python3.8/site-packages/keras/engine/compile_utils.py\", line 201, in __call__\n>>>     loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n>>> \n>>>   File \"/Users/meghamattikalli/opt/anaconda3/lib/python3.8/site-packages/keras/losses.py\", line 141, in __call__\n>>>     losses = call_fn(y_true, y_pred)\n>>> \n>>>   File \"/Users/meghamattikalli/opt/anaconda3/lib/python3.8/site-packages/keras/losses.py\", line 245, in call\n>>>     return ag_fn(y_true, y_pred, **self._fn_kwargs)\n>>> \n>>>   File \"/Users/meghamattikalli/opt/anaconda3/lib/python3.8/site-packages/keras/losses.py\", line 1664, in categorical_crossentropy\n>>>     return backend.categorical_crossentropy(\n>>> \n>>>   File \"/Users/meghamattikalli/opt/anaconda3/lib/python3.8/site-packages/keras/backend.py\", line 5009, in categorical_crossentropy\n>>>     return tf.nn.softmax_cross_entropy_with_logits(\n>>> "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "predictions = model.predict(imgs, verbose=0)\n",
    "print(\"predictions:\", predictions)\n",
    "\n",
    "print(\"Test our predictions using a batch size of:\", batch_size)\n",
    "pred = []\n",
    "for ind, i in enumerate(predictions):\n",
    "    print(word_dict[np.argmax(i)], end='   ')\n",
    "    pred.append(word_dict[np.argmax(i)])\n",
    "\n",
    "actual = []\n",
    "for i in labels:\n",
    "    print(word_dict[np.argmax(i)], end='   ')\n",
    "    actual.append(word_dict[np.argmax(i)])\n",
    "\n",
    "tot = 0\n",
    "correct = 0\n",
    "for i in range(len(labels)):\n",
    "    if labels[i] == pred[i]:\n",
    "        correct += 1\n",
    "    tot += 1\n",
    "\n",
    "print(\"Accuracy:\", 1.0 * correct / total)\n",
    "print(\"Actual labels:\", labels)\n",
    "print(\"Predictions:  \", predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
